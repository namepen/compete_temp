{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\home\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "path = '../home/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame([[1,2,3,4,5,6,7,8], [1,2,3,4,5,6,7,8], [1,2,3,4,5,6,7,8], [1,2,3,4,5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    4.0\n",
       "5    5.0\n",
       "6    6.0\n",
       "7    7.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_271', 'w_270', 'w_269', 'w_268']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['w_272', 'w_273', 'w_274', 'w_275', 'w_276', 'w_277', 'w_278', 'w_279']:\n",
    "    cols = [f'w_{int(col[2:])-i}' for i in range(1, 5, 1)]\n",
    "    break\n",
    "    x = sales_week.loc[item_num, cols].values\n",
    "    sales_week.loc[item_num, col] = reg.predict(x[np.newaxis, :])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../home/Downloads/media_sequence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['type'] == 'Clip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Welcome to Lost Lagoon!': 19.0,\n",
       " 'Tree Top City - Level 1': 17.0,\n",
       " 'Ordering Spheres': 61.0,\n",
       " 'Costume Box': 61.0,\n",
       " '12 Monkeys': 109.0,\n",
       " 'Tree Top City - Level 2': 25.0,\n",
       " \"Pirate's Tale\": 80.0,\n",
       " 'Treasure Map': 156.0,\n",
       " 'Tree Top City - Level 3': 26.0,\n",
       " 'Rulers': 126.0,\n",
       " 'Magma Peak - Level 1': 20.0,\n",
       " 'Slop Problem': 60.0,\n",
       " 'Magma Peak - Level 2': 22.0,\n",
       " 'Crystal Caves - Level 1': 18.0,\n",
       " 'Balancing Act': 72.0,\n",
       " 'Lifting Heavy Things': 118.0,\n",
       " 'Crystal Caves - Level 2': 24.0,\n",
       " 'Honey Cake': 142.0,\n",
       " 'Crystal Caves - Level 3': 19.0,\n",
       " 'Heavy, Heavier, Heaviest': 61.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame({'A' : [1,10,1,23], 'B' : [20,4,5,7], 'C' : [3,5,8,18]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([df.iloc[0], df.iloc[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C\n",
       "0   True   True   True\n",
       "1  False  False  False\n",
       "2   True   True   True\n",
       "3  False  False  False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df == [1,20,3]) | (df == [1,5,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B  C\n",
       "0  1  20  3\n",
       "2  1   5  8"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[((df == [1,20,3]).sum(axis=1) == 3) | ((df == [1,5,8]).sum(axis=1) == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "2  1  5  8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['card_hash'] = temp.apply(lambda x: card_info_hash(x), axis=1   )\n",
    "temp['device_hash'] = temp.apply(lambda x: device_hash(x), axis=1   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../home/Downloads/model_1.pickle', 'rb') as f:\n",
    "    pred_1 = pickle.load(f)\n",
    "    \n",
    "with open('../home/Downloads/model_2.pickle', 'rb') as f:\n",
    "    pred_2 = pickle.load(f)\n",
    "    \n",
    "with open('../home/Downloads/model_3.pickle', 'rb') as f:\n",
    "    pred_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_4 = pd.read_csv('sub_ver8.csv')\n",
    "pred_4['class'] = pred_4['class'].astype(str)\n",
    "pred_4.to_csv('sub_ver8.csv')\n",
    "              \n",
    "pred_5 = pd.read_csv('sub_kernelXception.csv')\n",
    "pred_5['class'] = pred_5['class'].astype(str)\n",
    "pred_5.to_csv('sub_sub_kernelXception.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(columns={'p1', 'p2', 'p3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['p1'] = np.squeeze(np.argmax(pred_1, axis=2), axis=1) +1\n",
    "pred['p2'] = np.squeeze(np.argmax(pred_2, axis=2), axis=1) + 1\n",
    "pred['p3'] = np.squeeze(np.argmax(pred_3, axis=2), axis=1) + 1\n",
    "pred['p4'] = pred_4['class']\n",
    "pred['p5'] = pred_5['class']\n",
    "\n",
    "pred['p1'] = pred['p1'].astype(str)\n",
    "pred['p2'] = pred['p2'].astype(str)\n",
    "pred['p3'] = pred['p3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_4['class'] = pred['p1']\n",
    "pred_4.to_csv('sub_ver14.csv', index=False)\n",
    "\n",
    "pred_4['class'] = pred['p2']\n",
    "pred_4.to_csv('sub_ver18.csv', index=False)\n",
    "\n",
    "pred_4['class'] = pred['p3']\n",
    "pred_4.to_csv('sub_ver20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_1 0.93400\n",
    "#pred 2 0.93591\n",
    "#pred_3 0.93208\n",
    "#pred_4 0.90387\n",
    "#pred_5 0.94691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights of the individual subs\n",
    "sub_weight = [0.93400**2, # public lb score (local cv would be better)\n",
    "              0.93591**2,\n",
    "             0.93208**2,\n",
    "             0.90387**2,\n",
    "             0.94691**2] # public lb score (local cv would be better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hlabel = 'img_file' \n",
    "Htarget = 'class'\n",
    "npt = 5 # number of places in target\n",
    "\n",
    "place_weights = {}\n",
    "for i in range(npt):\n",
    "    place_weights[i] = ( 1 / (i + 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_files = ['sub_ver8.csv', 'sub_ver14.csv', 'sub_ver20.csv','sub_ver18.csv', 'sub_kernelXception.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(place_weights)\n",
    "\n",
    "lg = len(sub_files)\n",
    "sub = [None]*lg\n",
    "for i, file in enumerate( sub_files ):\n",
    "    ## input files ##\n",
    "    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n",
    "    reader = csv.DictReader(open(file,\"r\"))\n",
    "    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output file ##\n",
    "out = open(\"submission.csv\", \"w\", newline='')\n",
    "writer = csv.writer(out)\n",
    "writer.writerow([Hlabel,Htarget])\n",
    "\n",
    "for p, row in enumerate(sub[0]):\n",
    "    target_weight = {}\n",
    "    for s in range(lg):\n",
    "        row1 = sub[s][p]\n",
    "        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n",
    "            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n",
    "    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n",
    "    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../home/Downloads/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['class'] = predict+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1 = pd.read_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2 = pd.read_csv(os.path.join(path, 'submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1['class_2'] = sub_2['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2.0\n",
    "e = K.epsilon()\n",
    "def focal_loss(y_pred, y_ture):\n",
    "    pt = y_pred * y_ture\n",
    "    CE = -K.log(pt+e)\n",
    "    FL = K.pow(1-pt, gamma) * CE\n",
    "    loss = K.sum(FL, axis=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([0.2, 0.2, 0.8])\n",
    "y_t = np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = y_pred * y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 1-pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.25 * np.power(one, 2) * np.log(pt+K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = K.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.clip(pt, e, (1-e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.pow(1-pt, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ainput = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 123.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.clamp(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "SIZE = 380\n",
    "NUM_CLASSES = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 고정\n",
    "#Fix seed number.\n",
    "seed = 200\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class ImageNetPolicy(object):\n",
    "    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n",
    "        Example:\n",
    "        >>> policy = ImageNetPolicy()\n",
    "        >>> transformed = policy(image)\n",
    "        Example as a PyTorch Transform:\n",
    "        >>> transform=transforms.Compose([\n",
    "        >>>     transforms.Resize(256),\n",
    "        >>>     ImageNetPolicy(),\n",
    "        >>>     transforms.ToTensor()])\n",
    "    \"\"\"\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.policies = [\n",
    "            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n",
    "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
    "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n",
    "            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n",
    "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
    "\n",
    "            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n",
    "            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n",
    "            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n",
    "\n",
    "            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n",
    "            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n",
    "            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
    "\n",
    "            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n",
    "            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n",
    "            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n",
    "            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n",
    "\n",
    "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
    "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
    "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
    "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
    "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __call__(self, img):\n",
    "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
    "        return self.policies[policy_idx](img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AutoAugment ImageNet Policy\"\n",
    "class SubPolicy(object):\n",
    "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
    "        ranges = {\n",
    "            \"shearX\": np.linspace(0, 0.3, 10),\n",
    "            \"shearY\": np.linspace(0, 0.3, 10),\n",
    "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
    "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
    "            \"rotate\": np.linspace(0, 30, 10),\n",
    "            \"color\": np.linspace(0.0, 0.9, 10),\n",
    "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
    "            \"solarize\": np.linspace(256, 0, 10),\n",
    "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
    "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"autocontrast\": [0] * 10,\n",
    "            \"equalize\": [0] * 10,\n",
    "            \"invert\": [0] * 10\n",
    "        }\n",
    "\n",
    "        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
    "        def rotate_with_fill(img, magnitude):\n",
    "            rot = img.convert(\"RGBA\").rotate(magnitude)\n",
    "            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n",
    "\n",
    "        func = {\n",
    "            \"shearX\": lambda img, magnitude: img.transform(\n",
    "                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
    "                Image.BICUBIC, fillcolor=fillcolor),\n",
    "            \"shearY\": lambda img, magnitude: img.transform(\n",
    "                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
    "                Image.BICUBIC, fillcolor=fillcolor),\n",
    "            \"translateX\": lambda img, magnitude: img.transform(\n",
    "                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
    "                fillcolor=fillcolor),\n",
    "            \"translateY\": lambda img, magnitude: img.transform(\n",
    "                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n",
    "                fillcolor=fillcolor),\n",
    "            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n",
    "            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n",
    "            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n",
    "            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n",
    "            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n",
    "            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])),\n",
    "            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])),\n",
    "            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])),\n",
    "            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n",
    "            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n",
    "            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n",
    "        }\n",
    "\n",
    "        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n",
    "        #     operation1, ranges[operation1][magnitude_idx1],\n",
    "        #     operation2, ranges[operation2][magnitude_idx2])\n",
    "        self.p1 = p1\n",
    "        self.operation1 = func[operation1]\n",
    "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
    "        self.p2 = p2\n",
    "        self.operation2 = func[operation2]\n",
    "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
    "\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n",
    "        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = ImageNetPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "#from keras.applications.xception import Xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = \"softmax\"\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = EfficientNetB4(include_top=False,\n",
    "                   #weights='imagenet',\n",
    "                    weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    #base_model.load_weights('../input/model-weight/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation=function, name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../home/Downloads/efficientnet_f2_bestqwk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, is_train=False, is_test=False,\n",
    "                 mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_test = is_test\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        if(self.is_test):\n",
    "            return self.test_generate(batch_x)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            #img = cv2.imread(os.path.join(crop_train_path, sample))\n",
    "            #img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = PIL.Image.open(os.path.join(crop_train_path, sample)).convert('RGB')\n",
    "            img = img.resize((SIZE, SIZE))\n",
    "            \n",
    "            if(self.is_augment):\n",
    "                #img = seq.augment_image(img)\n",
    "                img = trans(img)\n",
    "            img_np  = np.asarray(img)\n",
    "            if img_np.shape != (240, 240, 3):\n",
    "                img = img.convert('RGB')\n",
    "                img_np  = np.asarray(img)   \n",
    "            batch_images.append(img_np)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            #img = cv2.imread(os.path.join(crop_train_path, sample))\n",
    "            #img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = PIL.Image.open(os.path.join(crop_train_path, sample)).convert('RGB')\n",
    "            img = img.resize((SIZE, SIZE))\n",
    "            img  = np.asarray(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y\n",
    "    \n",
    "    def test_generate(self, batch_x):\n",
    "        batch_images = []\n",
    "        for sample in batch_x:\n",
    "            #img = cv2.imread(os.path.join(crop_train_path, sample))\n",
    "            #img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = PIL.Image.open(os.path.join(crop_test_path, sample)).convert('RGB')\n",
    "            img = img.resize((SIZE, SIZE))\n",
    "            img  = np.asarray(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        return batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_test_path = './test_crop/'\n",
    "test_x = submit['img_file']\n",
    "test_y = submit['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 16\n",
    "test_generator = My_Generator(test_x, test_y, batch_size=batch_size, is_train=False, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_generator:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hist = model.predict_generator(test_generator, steps=np.ceil(len(test_generator) / batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
